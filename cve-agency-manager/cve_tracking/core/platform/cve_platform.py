#!/usr/bin/python3
# ******************************************************************************
# Copyright (c) Huawei Technologies Co., Ltd. 2021-2021. All rights reserved.
# licensed under the Mulan PSL v2.
# You can use this software according to the terms and conditions of the Mulan PSL v2.
# You may obtain a copy of Mulan PSL v2 at:
#     http://license.coscl.org.cn/MulanPSL2
# THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY OR FIT FOR A PARTICULAR
# PURPOSE.
# See the Mulan PSL v2 for more details.
# ******************************************************************************/
import re
from collections import namedtuple
from functools import wraps

from bs4 import BeautifulSoup

from constant import Constant
from exception import RequestError
from logger import logger
from request import http


def match(regexes, component):
    """
    Decorator match commit, pr, issue
    :param regexes: regexes list
    :param component: commit, pr, issue
    :return: func
    """

    def _inner_decorator(func):
        @wraps(func)
        def _inner_match(crawler_text, patch_info):
            if patch_info.get('commits') or patch_info.get('pr'):
                return func(crawler_text, patch_info)
            match_list = list()
            for regex in regexes:
                match_list.extend(re.findall(pattern=regex, string=crawler_text))
            try:
                patch_info[component].extend(list(set(match_list)))
            except KeyError:
                logger.error(f'Patch info does not exist in field {component}')
            return func(crawler_text, patch_info)

        return _inner_match

    return _inner_decorator


class CvePlatform:
    """
    The parent class of cve reference URL
    """

    def __init__(self, cve_num=None, base_url=None):
        self.cve_num = cve_num
        self.base_url = base_url
        self._Patch = namedtuple('Patch', ['platform', 'commits', 'pr', 'issue'])

    @property
    def crawler_url(self):
        """
        Reference URL where cve information is located
        :return: url
        """
        return self.base_url + '/' + self.cve_num

    @property
    def patch_info(self):
        """
        Structure of cve patch information
        :return: instance of _Patch
        """
        return self._Patch(platform=self.crawler_url, commits=[], pr=[], issue=[])

    async def crawling_patch(self):
        """
        Crawl patch information from the cve reference website
        :return: patch info
        """
        try:
            _response = await http.get(self.crawler_url)
        except RequestError:
            return None

        if _response.error or not _response.text:
            logger.error(f'Failed to access URL {self.crawler_url}, detail: {_response.error}')
            return None

        formatted_text = self.format_text(_response.text)
        patch_info_dict = self.match_patch(formatted_text, dict(self.patch_info._asdict()))
        return patch_info_dict

    @staticmethod
    @match([Constant.COMMIT_REGEX, Constant.GIT_COMMIT_REGEX], 'commits')
    @match([Constant.PR_REGEX], 'pr')
    @match([Constant.ISSUE_REGEX], 'issue')
    def match_patch(text, patch_info):
        """
        Matching patch related links,Use decorator to find
        :param text: Crawled content
        :param patch_info: self.patch_info
        :return: None
        """
        # Matching url de-duplication
        for key, value in patch_info.items():
            if isinstance(value, list):
                patch_info[key] = list(set(value))

        logger.info(f'Find patch: {patch_info}')
        return patch_info

    @staticmethod
    def format_text(text):
        """
        Format the content obtained from the URL
        :return: Formatted content
        """
        html_text = BeautifulSoup(text, 'html.parser')
        return html_text.prettify()
