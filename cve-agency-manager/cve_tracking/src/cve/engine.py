#!/usr/bin/python3
import os
import csv
import re
import shutil
import signal
import time
from concurrent.futures import ThreadPoolExecutor
from queue import Queue
from collections import deque
from threading import Thread
from typing import Iterable
import requests

from .apply import apply_patch
from .logger import logger
from .httprequest import RemoteService
from .plantform import Ubuntu, Nvd, Debian, Bugzilla, Crawl
from .pipe import RequestRepeat, RequestsUrl, SavePipe, FileHandle
from .settings import (
    INTERNAL_SERVER,
    ENABLE_PLANTFORM,
    MAX_WORKERS,
    MAX_QUEUE,
    RECORD_FILE,
)
from .apply import AutoComment


class Cardiac:
    """
    The engine center
    """

    download_queue = Queue(maxsize=MAX_QUEUE)
    save_queue = Queue(maxsize=MAX_QUEUE)
    engine_queue = Queue(maxsize=MAX_QUEUE)
    pool = ThreadPoolExecutor(max_workers=MAX_WORKERS)
    download_thread = deque(maxlen=MAX_QUEUE)
    plantform = [Bugzilla, Debian, Ubuntu, Nvd]

    def __init__(self) -> None:
        self._active = True
        self.cve_infos = list()
        self._request_fingerprint = RequestRepeat()

    def _consume(self, cve, obj):
        print(f'[INFO] Crawling {str(obj.__name__)} platform')
        if not issubclass(obj, Crawl):
            raise RuntimeError("")

        crawl = obj(**cve)
        return RequestsUrl(
            url=crawl.start_url, crawl=crawl, callback=crawl.parse, start=True
        )

    def _record_base_info(self, cve):
        text = "CVE Information : {cve}".format(cve=str(cve))
        return SavePipe(text=text, crawl=Crawl(**cve))

    def _req_flow(self):
        """
        Sign up for various platforms
        Returns:

        """
        for cve in self.cve_infos:
            for plantform in self.plantform:
                if plantform.__name__ not in ENABLE_PLANTFORM:
                    continue
                yield self._consume(cve, obj=plantform)

            yield self._record_base_info(cve)

    def _internal_server(self, reuqest, pkg, commitid):
        first_char = pkg.lower()[0]
        success = False
        response = reuqest.request(
            url=INTERNAL_SERVER,
            method="post",
            json={
                "git_repo": f"upstream/{first_char}/{pkg}/{pkg}.git",
                "git_command": ["git-show", commitid, "--pretty=email"],
            },
            max_retry=1,
        )
        if response.text and response.status_code == requests.codes["ok"]:
            success = True
        return success, response

    def _downloader(self, req_flow):
        """
        downloader
        Returns:

        """
        request = RemoteService()

        def _github(request, response=None, success=False):
            if not success:
                response = request.request(url=req_flow.url, method="get", timeout=15)

                if response.status_code != requests.codes["ok"]:
                    self._download_failed(request=req_flow)
                    return

            callback = req_flow.callback(response)
            if isinstance(callback, Iterable):
                self._iterback(callback)

        if hasattr(req_flow, "is_patch") and getattr(req_flow, "is_patch"):
            success, response = self._internal_server(
                request,
                req_flow.crawl.pkg,
                req_flow.url.split("/")[-1].replace(".patch", ""),
            )
            _github(request, response=response, success=success)
        else:
            _github(request)

    def _download_failed(self, request):
        if hasattr(request, "start") and getattr(request, "start"):
            logger.warning("Start page %s failed to open" % request.url)
            return
        text = "File download failed:%s" % request.url
        logger.error(text)
        self.engine_queue.put(SavePipe(text=text, crawl=request.crawl))

    def _iterback(self, callback):
        while self._active:
            try:
                self.engine_queue.put(callback.send(None))
            except StopIteration:
                break

    def download(self):
        """
        downloader
        """
        while self._active:
            request_flow = self.download_queue.get()
            if not request_flow:
                break
            if self._request_fingerprint.request_seen(request_flow):
                continue
            future = self.pool.submit(self._downloader, request_flow)
            self.download_thread.append(future)

    def save_pipe(self):
        """
        Save data pipe
        """

        while self._active:
            save_handle = self.save_queue.get()
            if not save_handle:
                break

            callback = save_handle.save_process(save_handle.crawl)
            if isinstance(callback, Iterable):
                self._iterback(callback)

    def clear(self, queues):
        """Clear the stack of messages"""
        if not isinstance(queues, (list, tuple, set)):
            return
        for _queue in queues:
            if not isinstance(_queue, Queue):
                continue
            _queue.queue.clear()

    def stop(self):
        """
        Stop the service
        """

        self._active = False
        self.download_queue.put_nowait(None)
        self.engine_queue.put_nowait(None)
        self.save_queue.put_nowait(None)
        return not self._active

    def _read_csvfile(self, file, out_path, return_content=False):
        """
        Read the CSV file
        Args:
            file: CSV file

        Returns:

        """
        if not os.path.exists(file) or not os.path.isfile(file):
            logger.info("file not found:{}".format(file))
            return
        csv_contents = []
        try:
            csv_data = csv.reader(open(file, encoding="utf-8"))
            for cveinfo in csv_data:
                if len(cveinfo) != 3:
                    continue
                cve, pkg, versions = cveinfo
                versions = re.sub("\[|\]", "", versions).split(",")
                self._set_cve(cve=cve, pkg=pkg, versions=versions, out_path=out_path)
                csv_contents.append([pkg, cve])
        except csv.Error as error:
            logger.error(error)

        if return_content:
            return csv_contents

    def _set_cve(self, cve, pkg, versions, out_path):
        if isinstance(versions, str):
            versions = [versions]
        self.cve_infos.append(
            {"cve": cve, "pkg": pkg, "versions": versions, "out_path": out_path}
        )

    def start(self, args):
        """
        Start the service
        """
        # Get information such as CVE
        if args.f:
            self._read_csvfile(file=args.f, out_path=args.o)
        if args.cve:
            self._set_cve(cve=args.cve, pkg=args.name, versions=args.v, out_path=args.o)

        if not self.cve_infos:
            logger.info("There is no CVE information queried this time")
            self.stop()

        req_flow = self._req_flow()
        while self._active:
            try:
                flow = next(req_flow)
                self.engine_queue.put(flow)
            except StopIteration:
                break

    def scheduler(self):
        """
        Task scheduler
        """
        while self._active:
            task = self.engine_queue.get()
            if not task:
                break
            if isinstance(task, RequestsUrl):
                self.download_queue.put(task)

            if isinstance(task, SavePipe):
                self.save_queue.put(task)


class CrawlerProcess:
    """
    The process of data crawling
    """

    def __init__(self) -> None:
        self.engine = Cardiac()
        self._thread_container = [self._downloader, self._scheduler, self._save_pipe]
        self.end_signal = False
        self._interval = 6

    @property
    def finish(self):
        """Task queue consumption completed"""
        return all(
            [
                self.engine.download_queue.empty(),
                self.engine.save_queue.empty(),
                self.engine.engine_queue.empty(),
            ]
        )

    def _heartbeat(self):
        """
        Heartbeat mechanism
        Returns:

        """
        while True:
            time.sleep(self._interval)
            while len(self.engine.download_thread) > 0:
                thread = self.engine.download_thread.popleft()
                if not thread.done() and not self.end_signal:
                    self.engine.download_thread.append(thread)
            if self.end_signal or self.finish:
                self.end_signal = True
                self.engine.clear(
                    queues=[
                        self.engine.download_queue,
                        self.engine.save_queue,
                        self.engine.engine_queue,
                    ]
                )
                self.engine.stop()
                break

    def _stop(self, signum, frame):
        print("\nIt's in the process of closing .....")
        self.end_signal = True
        self._interval = 0
        self.engine.download_thread.clear()

    @property
    def _downloader(self):
        return Thread(target=self.engine.download)

    @property
    def _scheduler(self):
        return Thread(target=self.engine.scheduler)

    @property
    def _save_pipe(self):
        return Thread(target=self.engine.save_pipe)

    def _extract_info(self, args):
        print('[INFO] Start to extract info')
        file_handle = FileHandle(
            folder=args.o,
            branch=args.branch,
            cve=args.cve,
            pkg=args.name,
            csv_file=args.f,
            read_csv=self.engine._read_csvfile,
        )
        apply_result = None
        if args.cmd:
            apply_result = apply_patch(args.o, args.branch)
        print(f'[INFO] Apply patch result is {str(apply_result)}')
        file_handle.format_text(apply_result=apply_result)
        if args.issue:
            path = os.path.join(args.o, args.name + "-" + args.cve, RECORD_FILE)
            self._comment(
                file_handle,
                path,
                args.issue,
                args.name,
                cmd=args.cmd,
                branch=args.branch,
                cve=args.cve,
            )

    def _comment(self, file_handle, path, issue, repo, **kwargs):
        auto_comment = AutoComment()

        body = file_handle.extract_text(path)
        if not kwargs["cmd"]:
            body["apply_result"] = {branch: "Not apply" for branch in kwargs["branch"]}
        if kwargs["cmd"] and not body["apply_result"]:
            body["apply_result"] = {
                branch: "Apply failed" for branch in kwargs["branch"]
            }

        if not body.get("urls"):
            logger.warning(
                "%s has not found a valid patch file yet ." % kwargs.get("cve", "")
            )
            body = {
                "no_found": "[Find-Patch] 抱歉，当前工具暂未找到推荐补丁，请人工查找或者之后再尝试。\n"
                            "若您人工查找到补丁，烦请以 (查找平台:xxx 补丁链接:xxx) 的形式添加评论，我们将持续改进工具，不胜感激！"}
        auto_comment.comment(number=issue, body=body, repo=repo)

    def run(self, args):
        """
        Entrance to program execution
        """
        print('[INFO] Start to run cve_tracking')
        # Clears all files in the specified path
        if os.path.exists(args.o):
            shutil.rmtree(args.o)
        signal.signal(signal.SIGINT, self._stop)
        # Start Multiple Tasks
        while self._thread_container:
            task = self._thread_container.pop()
            task.start()

        self.engine.start(args)
        self._heartbeat()
        if self.end_signal:
            self._extract_info(args)


crawler = CrawlerProcess()
